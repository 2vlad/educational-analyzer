import { env } from '@/src/config/env'
import { modelsManager } from '@/src/config/models'
import { logger } from '@/src/utils/logger'
import {
  getPrompt,
  getProviderFamily,
  fillPromptTemplate,
  getPromptSnippet,
  type Metric,
} from '@/src/utils/prompts'
import { ClaudeProvider } from '@/src/providers/claude'
import { OpenAIProvider } from '@/src/providers/openai'
import { GeminiProvider } from '@/src/providers/gemini'
import { YandexProvider } from '@/src/providers/yandex'
import { OpenRouterProvider } from '@/src/providers/openrouter'
import { LLMProvider, GenerateResult, ProviderError } from '@/src/providers/types'

export class LLMService {
  private providers: Map<string, LLMProvider> = new Map()
  private currentProviderId: string

  constructor(providerId?: string) {
    this.currentProviderId = providerId || modelsManager.getDefaultModel()
    this.initializeProviders()
  }

  private initializeProviders() {
    console.log('üîß Initializing LLM providers...')
    console.log('Environment check:')
    console.log('- env.isServer:', env.isServer)
    console.log('- env.server exists:', !!env.server)

    // Initialize available providers based on API keys
    if (env.isServer && env.server) {
      // OpenRouter - unified provider for Claude, GPT, Gemini
      if (env.server.OPENROUTER_API_KEY) {
        console.log('‚úÖ Initializing OpenRouter provider')
        this.providers.set('openrouter', new OpenRouterProvider())
      } else {
        console.log('‚ö†Ô∏è OpenRouter API key not found')
      }

      // Legacy direct providers (kept for fallback)
      if (env.server.ANTHROPIC_API_KEY) {
        console.log('‚úÖ Initializing Anthropic provider')
        this.providers.set('anthropic', new ClaudeProvider())
      } else {
        console.log('‚ö†Ô∏è Anthropic API key not found')
      }

      if (env.server.OPENAI_API_KEY) {
        console.log('‚úÖ Initializing OpenAI provider')
        this.providers.set('openai', new OpenAIProvider())
      } else {
        console.log('‚ö†Ô∏è OpenAI API key not found')
      }

      if (env.server.GOOGLE_API_KEY) {
        console.log('‚úÖ Initializing Google provider')
        this.providers.set('google', new GeminiProvider())
      } else {
        console.log('‚ö†Ô∏è Google API key not found')
      }

      // Yandex - always direct
      if (env.server.YANDEX_API_KEY && env.server.YANDEX_FOLDER_ID) {
        console.log('‚úÖ Initializing Yandex provider')
        console.log('  - API Key length:', env.server.YANDEX_API_KEY.length)
        console.log('  - Folder ID:', env.server.YANDEX_FOLDER_ID)
        this.providers.set('yandex', new YandexProvider())
      } else {
        console.log('‚ö†Ô∏è Yandex provider not initialized:')
        console.log('  - API Key:', env.server?.YANDEX_API_KEY ? 'SET' : 'NOT SET')
        console.log('  - Folder ID:', env.server?.YANDEX_FOLDER_ID ? 'SET' : 'NOT SET')
      }
    } else {
      console.error('‚ùå Not on server or env.server is not available!')
    }

    console.log('ü§ñ LLMService initialized with providers:', Array.from(this.providers.keys()))

    if (this.providers.size === 0) {
      console.error('‚ùå CRITICAL: No LLM providers available! Analysis will fail.')
    }
  }

  public getProvider(providerId: string): LLMProvider {
    const modelConfig = modelsManager.getModelConfig(providerId)
    if (!modelConfig) {
      throw new Error(`Unknown model: ${providerId}`)
    }

    const provider = this.providers.get(modelConfig.provider)
    if (!provider) {
      throw new Error(`Provider not available: ${modelConfig.provider}`)
    }

    return provider
  }

  async analyze(
    content: string,
    metric: Metric,
    customPromptText?: string,
  ): Promise<GenerateResult> {
    const modelConfig = modelsManager.getModelConfig(this.currentProviderId)
    if (!modelConfig) {
      throw new Error(`Model configuration not found: ${this.currentProviderId}`)
    }

    // Get prompt for the provider family
    const providerFamily = getProviderFamily(this.currentProviderId)
    // Use custom prompt text if provided, otherwise load from file
    let prompt = customPromptText || getPrompt(providerFamily, metric)

    // For custom prompts, ensure JSON format for proper parsing
    if (customPromptText && !customPromptText.includes('json')) {
      prompt = `${customPromptText}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º:
\`\`\`json
{
  "score": -2|-1|0|1|2,
  "comment": "–∫—Ä–∞—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–º–∞–∫—Å 150 —Å–∏–º–≤–æ–ª–æ–≤)",
  "examples": [
    "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –∏–ª–ª—é—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤–∞—à—É –æ—Ü–µ–Ω–∫—É",
    "–ï—â–µ –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä –∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–∞"
  ],
  "detailed_analysis": "–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –ø–æ –¥–∞–Ω–Ω–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
  "suggestions": [
    "–ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é",
    "–ï—â–µ –æ–¥–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è"
  ]
}
\`\`\`

–ú–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{{content}}`
    }

    const filledPrompt = fillPromptTemplate(prompt, content)

    console.log('\nüìù LLMService.analyze()')
    console.log('Metric:', metric)
    console.log('Model:', this.currentProviderId)
    console.log('Provider:', providerFamily)
    console.log('Content length:', content.length)
    console.log('Prompt length:', filledPrompt.length)

    // Log request start
    const analysisId = globalThis.crypto.randomUUID()
    logger.llmRequestStart({
      analysisId,
      metric,
      model: this.currentProviderId,
      promptLength: filledPrompt.length,
      contentLength: content.length,
    })

    try {
      // Get provider and generate
      const provider = this.getProvider(this.currentProviderId)
      const result = await provider.generate(prompt, content, {
        model: modelConfig.model,
        temperature: modelConfig.temperature,
        maxTokens: modelConfig.maxTokens,
        timeoutMs: env.server?.REQUEST_TIMEOUT || 30000,
      })

      // Log success
      logger.llmRequestComplete({
        analysisId,
        metric,
        model: this.currentProviderId,
        duration: result.durationMs,
        tokensUsed: result.tokensUsed,
        success: true,
      })

      return result
    } catch (error) {
      // Log error
      logger.llmRequestError({
        analysisId,
        metric,
        model: this.currentProviderId,
        error: error instanceof Error ? error.message : 'Unknown error',
        retryCount: 0,
        promptSnippet: getPromptSnippet(filledPrompt),
      })

      throw error
    }
  }

  async analyzeWithRetry(
    content: string,
    metric: Metric,
    maxRetries?: number,
    customPromptText?: string,
  ): Promise<GenerateResult> {
    const retries = maxRetries || env.server?.MAX_RETRIES || 3
    let lastError: Error | undefined

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        const result = await this.analyze(content, metric, customPromptText)

        if (attempt > 1) {
          logger.llmSuccess({ metric, attempt })
        }

        return result
      } catch (error) {
        lastError = error as Error

        // Check if error is retryable
        if (error instanceof ProviderError && !error.retryable) {
          throw error
        }

        logger.llmRetry({
          metric,
          attempt,
          error: lastError.message,
        })

        // Add exponential backoff delay before retry (except on last attempt)
        if (attempt < retries) {
          const delay = Math.min(1000 * Math.pow(2, attempt - 1), 10000) // 1s, 2s, 4s, max 10s
          console.log(`‚è≥ Waiting ${delay}ms before retry attempt ${attempt + 1}/${retries}...`)
          await new Promise((resolve) => globalThis.setTimeout(resolve, delay))
        }

        // If this was the last attempt and model switching is enabled, try fallback
        if (attempt === retries && modelsManager.isModelSwitchingEnabled()) {
          const fallbackModel = modelsManager.getNextFallbackModel(this.currentProviderId)

          if (fallbackModel) {
            logger.modelFallback({ metric, fallbackModel })

            // Switch to fallback model and try once more
            const oldModel = this.currentProviderId
            this.currentProviderId = fallbackModel

            logger.modelSwitch({
              from: oldModel,
              to: fallbackModel,
              reason: 'Max retries reached',
            })

            try {
              return await this.analyze(content, metric, customPromptText)
            } catch (fallbackError) {
              // Restore original model
              this.currentProviderId = oldModel
              throw fallbackError
            }
          }
        }
      }
    }

    throw lastError || new Error('Max retries reached')
  }

  async generateTitle(content: string, providerId?: string): Promise<GenerateResult> {
    const modelId = providerId || this.currentProviderId
    const modelConfig = modelsManager.getModelConfig(modelId)
    if (!modelConfig) {
      throw new Error(`Model configuration not found: ${modelId}`)
    }

    const titlePrompt = `–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –∏ –¥–∞–π –µ–º—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (3-6 —Å–ª–æ–≤), –∫–æ—Ç–æ—Ä–æ–µ —Ç–æ—á–Ω–æ –æ—Ç—Ä–∞–∂–∞–µ—Ç —Ç–µ–º—É. 
–ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Å–ª–æ–≤ —Ç–∏–ø–∞ "–û—Å–Ω–æ–≤—ã", "–í–≤–µ–¥–µ–Ω–∏–µ", "–£—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª". 
–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –º–µ—Ç–æ–¥—ã –∏–ª–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º, –±–µ–∑ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.

–ú–∞—Ç–µ—Ä–∏–∞–ª:
${content.substring(0, 1500)}...

–ù–∞–∑–≤–∞–Ω–∏–µ:`

    try {
      const provider = this.getProvider(modelId)
      const result = await provider.generate(titlePrompt, '', {
        model: modelConfig.model,
        temperature: 0.3,
        maxTokens: 50,
        timeoutMs: 5000,
      })

      // Clean up the title
      if (result.comment) {
        result.comment = result.comment.trim().replace(/["`']/g, '').substring(0, 100)
      }

      return result
    } catch (error) {
      console.error('Failed to generate title:', error)
      return {
        score: 0,
        comment: '–£—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª',
        examples: [],
        model: modelId,
        durationMs: 0,
        raw: null,
        provider: 'unknown',
      }
    }
  }

  async analyzeWithModel(
    content: string,
    metric: Metric,
    providerId: string,
    customPromptText?: string,
  ): Promise<GenerateResult> {
    const oldModel = this.currentProviderId
    this.currentProviderId = providerId

    try {
      logger.modelSwitch({
        from: oldModel,
        to: providerId,
        reason: 'Explicit model selection',
      })

      return await this.analyze(content, metric, customPromptText)
    } finally {
      this.currentProviderId = oldModel
    }
  }

  getCurrentModel(): string {
    return this.currentProviderId
  }

  getAvailableModels(): string[] {
    return modelsManager.getAvailableModels()
  }

  /**
   * Analyze coherence and connections between multiple lessons
   * @param lessons Array of lessons with titles and content
   * @param providerId Optional specific model to use
   * @returns Analysis of lesson coherence
   */
  async analyzeCoherence(
    lessons: Array<{ title: string; content: string }>,
    providerId?: string,
  ): Promise<{
    score: number
    summary: string
    strengths: string[]
    issues: string[]
    suggestions: string[]
  }> {
    const modelId = providerId || this.currentProviderId
    const modelConfig = modelsManager.getModelConfig(modelId)
    if (!modelConfig) {
      throw new Error(`Model configuration not found: ${modelId}`)
    }

    console.log('[Coherence Analysis] Starting analysis...')
    console.log('[Coherence Analysis] Model:', modelId)
    console.log('[Coherence Analysis] Number of lessons:', lessons.length)

    // Validate lesson content
    const validLessons = lessons.filter(
      (lesson) => lesson.content && lesson.content.trim().length > 0,
    )
    console.log('[Coherence Analysis] Valid lessons with content:', validLessons.length)

    if (validLessons.length < 2) {
      console.error('[Coherence Analysis] Not enough lessons with content')
      return {
        score: 0,
        summary: `–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É—Ä–æ–∫–æ–≤ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ (–Ω–∞–π–¥–µ–Ω–æ ${validLessons.length} –∏–∑ ${lessons.length})`,
        strengths: [],
        issues: ['–ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —É—Ä–æ–∫–æ–≤ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–µ–∫—Å—Ç –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –±—ã–ª–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ'],
        suggestions: ['–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã —É—Ä–æ–∫–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–µ–∫—Å—Ç –∏ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'],
      }
    }

    // Create a compact representation of lessons for analysis
    const lessonsOverview = validLessons
      .map((lesson, i) => {
        // Take first 800 chars of each lesson for better context
        const preview = lesson.content.substring(0, 800)
        return `–£—Ä–æ–∫ ${i + 1}: "${lesson.title}"\n${preview}${lesson.content.length > 800 ? '...' : ''}`
      })
      .join('\n\n---\n\n')

    console.log('[Coherence Analysis] Overview length:', lessonsOverview.length, 'chars')

    const coherencePrompt = `–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —É—á–µ–±–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–≤—è–∑–Ω–æ—Å—Ç—å –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å ${validLessons.length} —É—Ä–æ–∫–æ–≤.

–£—Ä–æ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
${lessonsOverview}

–û—Ü–µ–Ω–∏ —Å–≤—è–∑–Ω–æ—Å—Ç—å –ø–æ —à–∫–∞–ª–µ –æ—Ç -2 –¥–æ +2:
- -2: –£—Ä–æ–∫–∏ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ —Å–≤—è–∑–∞–Ω—ã, —Ö–∞–æ—Ç–∏—á–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- -1: –°–ª–∞–±–∞—è —Å–≤—è–∑—å, –µ—Å—Ç—å –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã
- 0: –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è —Å–≤—è–∑—å, –º–∞—Ç–µ—Ä–∏–∞–ª —Ä–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã–π –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π
- +1: –•–æ—Ä–æ—à–∞—è —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å, –ª–æ–≥–∏—á–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- +2: –û—Ç–ª–∏—á–Ω–∞—è —Å–≤—è–∑–Ω–æ—Å—Ç—å, –∫–∞–∂–¥—ã–π —É—Ä–æ–∫ –ø–ª–∞–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: 
1. –¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –æ–±—ä–µ–∫—Ç–æ–º
2. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ JSON
3. –ù–∏–∫–∞–∫–∏—Ö markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–π (—Ç—Ä–æ–π–Ω—ã—Ö –±—ç–∫—Ç–∏–∫–æ–≤ —Å json –∏–ª–∏ –±–µ–∑)
4. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π JSON –æ–±—ä–µ–∫—Ç

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
{
  "score": -2,
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—â–µ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
  "strengths": ["–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 1", "–°–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ 2"],
  "issues": ["–ü—Ä–æ–±–ª–µ–º–∞ 1", "–ü—Ä–æ–±–ª–µ–º–∞ 2"],
  "suggestions": ["–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 1", "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 2"]
}

–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:
{"score": 1, "summary": "–£—Ä–æ–∫–∏ —Ö–æ—Ä–æ—à–æ —Å–≤—è–∑–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π.", "strengths": ["–õ–æ–≥–∏—á–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å"], "issues": ["–ò–Ω–æ–≥–¥–∞ —Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã"], "suggestions": ["–î–æ–±–∞–≤–∏—Ç—å —Å–≤—è–∑—É—é—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã"]}

{"score": -1, "summary": "–°–≤—è–∑—å –º–µ–∂–¥—É —É—Ä–æ–∫–∞–º–∏ —Å–ª–∞–±–∞—è, –µ—Å—Ç—å –ø—Ä–æ–±–µ–ª—ã.", "strengths": ["–ö–∞–∂–¥—ã–π —É—Ä–æ–∫ —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω"], "issues": ["–ù–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", "–ú–∞—Ç–µ—Ä–∏–∞–ª —Ä–∞–∑—Ä–æ–∑–Ω–µ–Ω–Ω—ã–π"], "suggestions": ["–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫—É—Ä—Å–∞", "–î–æ–±–∞–≤–∏—Ç—å –≤–≤–æ–¥–Ω—ã–µ —á–∞—Å—Ç–∏"]}

–¢–µ–ø–µ—Ä—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —É—Ä–æ–∫–∏ –∏ –≤–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –æ–±—ä–µ–∫—Ç:`

    try {
      const provider = this.getProvider(modelId)
      console.log('[Coherence Analysis] Calling LLM provider...')

      const result = await provider.generate(coherencePrompt, '', {
        model: modelConfig.model,
        temperature: 0.3,
        maxTokens: 1500,
        timeoutMs: 30000, // Increased timeout
      })

      console.log('[Coherence Analysis] Raw LLM response:', result.comment?.substring(0, 200))

      // Parse the response
      let parsed: {
        score?: number
        summary?: string
        strengths?: string[]
        issues?: string[]
        suggestions?: string[]
      }

      try {
        // Try to extract JSON from the response - support multiple formats
        let jsonText = result.comment || ''

        console.log('[Coherence Analysis] Original response length:', jsonText.length)
        console.log('[Coherence Analysis] First 500 chars:', jsonText.substring(0, 500))

        // Remove markdown code blocks
        jsonText = jsonText.replace(/```json\s*/g, '').replace(/```\s*/g, '')

        // Trim whitespace
        jsonText = jsonText.trim()

        // Try to find JSON object
        const jsonMatch = jsonText.match(/\{[\s\S]*\}/)
        if (jsonMatch) {
          console.log('[Coherence Analysis] Found JSON in response, length:', jsonMatch[0].length)
          console.log('[Coherence Analysis] JSON to parse:', jsonMatch[0].substring(0, 300))
          parsed = JSON.parse(jsonMatch[0])
          console.log('[Coherence Analysis] Parsed successfully:', JSON.stringify(parsed))
        } else {
          console.error('[Coherence Analysis] No JSON found in response')
          console.error('[Coherence Analysis] Full response:', jsonText)
          throw new Error('No JSON found in response')
        }
      } catch (parseError) {
        console.error('[Coherence Analysis] Failed to parse JSON:', parseError)
        console.error(
          '[Coherence Analysis] Parse error details:',
          parseError instanceof Error ? parseError.message : 'Unknown',
        )
        console.error(
          '[Coherence Analysis] Raw response (first 1000 chars):',
          result.comment?.substring(0, 1000),
        )

        // Return a fallback analysis with the raw comment
        return {
          score: 0,
          summary:
            result.comment || '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ —É—Ä–æ–∫–æ–≤',
          strengths: [],
          issues: [],
          suggestions: [
            '–û—Ç–≤–µ—Ç AI –Ω–µ –±—ã–ª –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å',
          ],
        }
      }

      // Validate and return parsed data
      return {
        score: typeof parsed.score === 'number' ? parsed.score : 0,
        summary: parsed.summary || '–ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω',
        strengths: Array.isArray(parsed.strengths) ? parsed.strengths : [],
        issues: Array.isArray(parsed.issues) ? parsed.issues : [],
        suggestions: Array.isArray(parsed.suggestions) ? parsed.suggestions : [],
      }
    } catch (error) {
      console.error('[Coherence Analysis] Error:', error)
      return {
        score: 0,
        summary: '–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Å–≤—è–∑–Ω–æ—Å—Ç–∏ —É—Ä–æ–∫–æ–≤',
        strengths: [],
        issues: [],
        suggestions: [
          '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI –º–æ–¥–µ–ª–∏',
          '–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–ø—ã—Ç–∫—É –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å',
        ],
      }
    }
  }
}

// Export singleton for convenience
export const llmService = new LLMService()
